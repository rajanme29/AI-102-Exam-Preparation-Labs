{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f724a95",
   "metadata": {},
   "source": [
    "# Creating a Custom Agent with MCP Tools in Azure AI\n",
    "\n",
    "This notebook demonstrates the end-to-end process of creating a custom agent in Azure AI that utilizes a Microsoft Custom Copilot (MCP) tool. We will cover the following steps:\n",
    "1.  **Setup & Configuration**: Authenticate and initialize the necessary clients.\n",
    "2.  **Tool Definition**: Configure an MCP tool to connect to an external API.\n",
    "3.  **Agent Creation**: Define and register a new agent with our custom tool.\n",
    "4.  **Agent Interaction**: Engage in a conversation with the agent, handle the tool approval flow, and retrieve the final response.\n",
    "5.  **Response Analysis**: Inspect the detailed output from the agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e0ee6",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n",
    "\n",
    "Before you begin, ensure you have the following:\n",
    "*   An Azure AI Project.\n",
    "*   A deployed model within your project (e.g., a GPT-4 model).\n",
    "*   The necessary permissions to create agents and interact with the project.\n",
    "*   A `.env` file in the same directory as this notebook with the following variables:\n",
    "\n",
    "```\n",
    "PROJECT_ENDPOINT=\"<YOUR_AZURE_AI_PROJECT_ENDPOINT>\"\n",
    "MODEL_DEPLOYMENT_NAME=\"<YOUR_MODEL_DEPLOYMENT_NAME>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185db9e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0448db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import MCPTool, PromptAgentDefinition\n",
    "from openai.types.responses.response_input_param import McpApprovalResponse, ResponseInputParam\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712b3f1",
   "metadata": {},
   "source": [
    "## 2. Setup and Configuration\n",
    "\n",
    "First, we'll load the environment variables from our `.env` file. Then, we will create an `AIProjectClient` to manage resources within our Azure AI project and an `OpenAIClient` to interact with the conversational agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve configuration from environment variables\n",
    "project_endpoint = os.environ.get('PROJECT_ENDPOINT')\n",
    "model_deployment = os.environ.get('MODEL_DEPLOYMENT_NAME')\n",
    "\n",
    "if not project_endpoint or not model_deployment:\n",
    "    raise ValueError(\"Please set PROJECT_ENDPOINT and MODEL_DEPLOYMENT_NAME in your .env file.\")\n",
    "\n",
    "# Use DefaultAzureCredential for authentication\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Create the main client to interact with the Azure AI Project\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "# Get the OpenAI-compatible client for conversational interactions\n",
    "openai_client = project_client.get_openai_client()\n",
    "\n",
    "print(f\"Clients initialized for project endpoint: {project_endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1d383",
   "metadata": {},
   "source": [
    "## 3. Define the MCP Tool\n",
    "\n",
    "Here, we define the MCP tool configuration. The agent will use this tool to call an external API.\n",
    "\n",
    "*   `server_label`: A unique identifier for the tool within the agent's configuration.\n",
    "*   `server_url`: The URL pointing to the OpenAPI specification or the API endpoint for the MCP server.\n",
    "*   `require_approval`: Determines if the agent must seek user approval before calling the tool. Options are `never`, `always`, or `auto`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe440a08",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37df2e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP Tool 'api-specs' configured for URL: https://learn.microsoft.com/api/mcp\n"
     ]
    }
   ],
   "source": [
    "# Define the configuration for the MCP server tool\n",
    "server_label = 'api-specs'\n",
    "server_url = 'https://learn.microsoft.com/api/mcp' # This is a public Microsoft Learn API endpoint\n",
    "\n",
    "mcp_tool = MCPTool(\n",
    "    server_label=server_label,\n",
    "    server_url=server_url,\n",
    "    require_approval='always'  # 'never' allows the agent to call the tool without asking for permission\n",
    ")\n",
    "\n",
    "print(f\"MCP Tool '{server_label}' configured for URL: {server_url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4977fe3",
   "metadata": {},
   "source": [
    "## 4. Create the Agent\n",
    "\n",
    "Now, we create the agent. We provide it with a name, a set of instructions defining its persona and purpose, the model it should use, and the list of tools it has access to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0ffcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n",
      "  ID: learn-doc-agent:1\n",
      "  Name: learn-doc-agent\n",
      "  Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Define the agent's properties\n",
    "agent_name = \"learn-doc-agent\"\n",
    "agent_instructions = \"\"\"\n",
    "You are a helpful assistant designed to find relevant documentation on Microsoft Learn.\n",
    "Use the provided MCP tools to answer user questions about Microsoft products and services.\n",
    "Prefer calling the MCP tools when they can improve the accuracy of your answer.\n",
    "\"\"\"\n",
    "\n",
    "# Create a new version of the agent\n",
    "my_agent = project_client.agents.create_version(\n",
    "    agent_name=agent_name,\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=model_deployment,\n",
    "        instructions=agent_instructions,\n",
    "        tools=[mcp_tool]\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"Agent created successfully!\")\n",
    "print(f\"  ID: {my_agent.id}\")\n",
    "print(f\"  Name: {my_agent.name}\")\n",
    "print(f\"  Version: {my_agent.version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f553ad",
   "metadata": {},
   "source": [
    "## 5. Interact with the Agent\n",
    "\n",
    "With our agent created, we can now start a conversation.\n",
    "\n",
    "### 5.1. Create a Conversation Thread\n",
    "First, we create a new conversation thread, which will maintain the context of our interaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0329ce41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a new conversation thread with ID: conv_3efd6544ad8a3f3300uWuoy7IzMuMkch5WymGRR0V945irbwoi\n"
     ]
    }
   ],
   "source": [
    "# Create a new conversation thread for the agent\n",
    "conversation = openai_client.conversations.create()\n",
    "print(f\"Created a new conversation thread with ID: {conversation.id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa6140",
   "metadata": {},
   "source": [
    "### 5.2. Send the Initial Request\n",
    "We send our first message. The agent will analyze this request and determine that it needs to use the configured MCP tool to answer it. Because we set `require_approval='never'`, it will proceed directly. If it were set to `always` or `auto`, the flow would pause here for an approval step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ebb88c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial request sent to the agent.\n",
      "Agent response: \n"
     ]
    }
   ],
   "source": [
    "# Send the initial user request to the agent\n",
    "user_prompt = \"Find one relevant Microsoft Learn page about Machine Learning Model creation\"\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    input=user_prompt,\n",
    "    extra_body={\"agent\": {\"name\": my_agent.name, \"type\": \"agent_reference\"}},\n",
    ")\n",
    "\n",
    "print(\"Initial request sent to the agent.\")\n",
    "print(f\"Agent response: {response.output_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9b985",
   "metadata": {},
   "source": [
    "## 6. Analyze the Response\n",
    "\n",
    "Let's create a helper function to print the components of the agent's response object. This helps us understand the steps the agent took, including any tool calls it made.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a39eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "AGENT RESPONSE DETAILS\n",
      "====================\n",
      "\n",
      "--- Item 1: type = mcp_list_tools ---\n",
      "  Server Label: api-specs\n",
      "\n",
      "--- Item 2: type = mcp_approval_request ---\n",
      "  Server Label: api-specs\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_response(resp):\n",
    "    \"\"\"A helper function to print the agent's response object in a readable format.\"\"\"\n",
    "    print(\"=\" * 20)\n",
    "    print(\"AGENT RESPONSE DETAILS\")\n",
    "    print(\"=\" * 20)\n",
    "    for i, item in enumerate(resp.output):\n",
    "        print(f\"\\n--- Item {i+1}: type = {item.type} ---\")\n",
    "        if getattr(item, \"text\", None):\n",
    "            # Limit text output to avoid flooding the screen\n",
    "            print(f\"  Text: {item.text[:500]}...\")\n",
    "        if getattr(item, \"role\", None):\n",
    "            print(f\"  Role: {item.role}\")\n",
    "        if getattr(item, \"server_label\", None):\n",
    "            print(f\"  Server Label: {item.server_label}\")\n",
    "        if item.type == \"tool_response\":\n",
    "            print(f\"  Tool Name: {item.name}\")\n",
    "            print(f\"  Arguments: {item.arguments}\")\n",
    "            print(f\"  Output: {item.output[:500]}...\")\n",
    "\n",
    "# Print the detailed response from the last interaction\n",
    "pretty_print_response(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
